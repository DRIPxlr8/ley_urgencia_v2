"""
EVALUACI√ìN DEL MODELO CON form_MPP.xlsx
Eval√∫a accuracy solo en los casos que tienen validaci√≥n manual
"""
import pandas as pd
import numpy as np
import joblib
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("üîç EVALUACI√ìN DEL MODELO CON form_MPP.xlsx")
print("="*80)

# ============================================================
# 1. CARGAR MODELO
# ============================================================
print("\nüìÇ Cargando modelo entrenado...")

try:
    modelo = joblib.load('modelo_ley_urgencia.pkl')
    metadata = joblib.load('modelo_metadata.pkl')
    print("   ‚úÖ Modelo cargado exitosamente")
except FileNotFoundError:
    print("   ‚ùå ERROR: No se encontr√≥ el modelo entrenado")
    print("   Ejecuta primero: python entrenar_modelo_final.py")
    exit(1)

print(f"\n   Modelo: {metadata.get('model_type', 'N/A')}")
print(f"   Features: {len(metadata['features'])}")
print(f"   Accuracy en entrenamiento: {metadata.get('accuracy_test', 0)*100:.2f}%")

# ============================================================
# 2. CARGAR DATOS DE EVALUACI√ìN
# ============================================================
print("\nüìÇ Cargando form_MPP.xlsx...")

df = pd.read_excel('data/form_MPP.xlsx')

print(f"   Total registros: {len(df):,}")

# Verificar columna de validaci√≥n
if 'Validacion' not in df.columns:
    print("   ‚ùå ERROR: No se encontr√≥ columna 'Validacion'")
    exit(1)

# Filtrar solo casos CON validaci√≥n manual
df_con_validacion = df[df['Validacion'].notna()].copy()

print(f"   Casos CON validaci√≥n: {len(df_con_validacion):,}")
print(f"   Casos SIN validaci√≥n: {len(df) - len(df_con_validacion):,}")

if len(df_con_validacion) == 0:
    print("   ‚ùå No hay casos con validaci√≥n para evaluar")
    exit(1)

print(f"\n   Distribuci√≥n de validaciones:")
print(df_con_validacion['Validacion'].value_counts())

# ============================================================
# 3. PREPARAR FEATURES
# ============================================================
print("\nüîß Preparando features...")

# Mapear nombres de columnas de form_MPP a Base.xlsx
mapeo_columnas = {
    'Presi√≥n Arterial Sist√≥lica': 'PAS',
    'Presi√≥n Arterial Diast√≥lica': 'PAD',
    'Presi√≥n Arterial Media': 'PAM',
    'Saturaci√≥n Ox√≠geno': 'Saturacion_O2',
    'Frecuencia Card√≠aca': 'FC',
    'Frecuencia Respiratoria': 'FR',
    'Nitr√≥geno Ureico': 'BUN',
    'Antecedentes Card√≠acos': 'Antecedentes_Cardiacos',
    'Antecedentes Diab√©ticos': 'Antecedentes_Diabeticos',
    'Antecedentes de Hipertensi√≥n Arterial': 'Antecedentes_HTA',
    'FIO2 > o igual a 50%': 'FIO2 > o igual a 50%',
    'Ventilaci√≥n Mec√°nica': 'Ventilacion_Mecanica',
    'Cirug√≠a Realizada': 'Cirugia',
    'Cirug√≠a mismo d√≠a ingreso': 'Cirugia_mismo_dia',
    'Hemodinamia Realizada': 'Hemodinamia',
    'Hemodinamia mismo d√≠a ingreso ': 'Hemodinamia_mismo_dia',
    'Endoscopia mismo d√≠a ingreso': 'Endoscopia_mismo_dia',
    'Di√°lisis': 'Dialisis',
    'Tromb√≥lisis': 'Tromb√≥lisis',
    'Tromb√≥lisis mismo d√≠a ingreso': 'Tromb√≥lisis mismo d√≠a ingreso',
    'Troponinas Alteradas': 'Troponinas',
    'ECG Alterado': 'ECG_alterado',
    'RNM Protocolo Stroke': 'RNM_Stroke',
    'Compromiso Conciencia': 'Compromiso_Conciencia'
}

# Crear DataFrame de trabajo
df_work = df_con_validacion.copy()

# Renombrar columnas seg√∫n mapeo
for col_form, col_base in mapeo_columnas.items():
    if col_form in df_work.columns:
        df_work[col_base] = df_work[col_form]

# Asegurar que existen las columnas que el modelo espera
for feature in metadata['features']:
    if feature not in df_work.columns:
        # Si es feature derivada, la calcularemos
        if feature in metadata.get('feature_engineering', []):
            continue
        # Si no existe, crear con NaN
        df_work[feature] = np.nan

# ============================================================
# 4. FEATURE ENGINEERING (IGUAL QUE EN ENTRENAMIENTO)
# ============================================================
print("\n‚öôÔ∏è  Feature Engineering...")

# Normalizar nombres para PAS, PAD, etc. si ya existen
if 'Presi√≥n Arterial Sist√≥lica' in df_work.columns and 'PAS' not in df_work.columns:
    df_work['PAS'] = df_work['Presi√≥n Arterial Sist√≥lica']
if 'Presi√≥n Arterial Diast√≥lica' in df_work.columns and 'PAD' not in df_work.columns:
    df_work['PAD'] = df_work['Presi√≥n Arterial Diast√≥lica']
if 'Saturaci√≥n Ox√≠geno' in df_work.columns and 'Saturacion_O2' not in df_work.columns:
    df_work['Saturacion_O2'] = df_work['Saturaci√≥n Ox√≠geno']
if 'Frecuencia Card√≠aca' in df_work.columns and 'FC' not in df_work.columns:
    df_work['FC'] = df_work['Frecuencia Card√≠aca']
if 'Frecuencia Respiratoria' in df_work.columns and 'FR' not in df_work.columns:
    df_work['FR'] = df_work['Frecuencia Respiratoria']

# Convertir columnas num√©ricas a numeric
numeric_cols = ['PAS', 'PAD', 'Saturacion_O2', 'FC', 'FR', 'Glasgow', 
                'PCR', 'Hemoglobina', 'Creatinina', 'BUN', 'Sodio', 'Potasio',
                'FIO2', 'Temperatura en ¬∞C']
for col in numeric_cols:
    if col in df_work.columns:
        df_work[col] = pd.to_numeric(df_work[col], errors='coerce')

# Convertir binarias Si/No a 1/0
binary_cols = list(metadata['binary_features'])
for col in binary_cols:
    if col in df_work.columns and df_work[col].dtype == 'object':
        df_work[col] = df_work[col].map({'Si': 1, 'S√≠': 1, 'si': 1, 's√≠': 1, 'No': 0, 'no': 0, 'NO': 0})
        df_work[col] = pd.to_numeric(df_work[col], errors='coerce').fillna(0).astype(int)

# Crear features derivadas
df_work['Ratio_SatO2_FR'] = df_work['Saturacion_O2'] / (df_work['FR'] + 1)
df_work['Ratio_PAS_Glasgow'] = df_work['PAS'] / (df_work['Glasgow'] + 1)
df_work['Presion_Pulso'] = df_work['PAS'] - df_work['PAD']
df_work['Presion_Media_Calc'] = (df_work['PAS'] + 2 * df_work['PAD']) / 3

df_work['Flag_Hipotension'] = (df_work['PAS'] < 100).astype(int)
df_work['Flag_Hipertension_Critica'] = (df_work['PAS'] > 180).astype(int)
df_work['Flag_Hipoxemia'] = (df_work['Saturacion_O2'] < 92).astype(int)
df_work['Flag_Taquipnea'] = (df_work['FR'] > 24).astype(int)
df_work['Flag_Glasgow_Bajo'] = (df_work['Glasgow'] < 13).astype(int)

df_work['Score_Gravedad'] = (
    df_work['Flag_Hipotension'] * 2 +
    df_work['Flag_Hipertension_Critica'] * 1.5 +
    df_work['Flag_Hipoxemia'] * 2 +
    df_work['Flag_Taquipnea'] * 1.5 +
    df_work['Flag_Glasgow_Bajo'] * 2
)

df_work['SatO2_x_Glasgow'] = df_work['Saturacion_O2'] * df_work['Glasgow']
df_work['PA_x_FR'] = df_work['PAS'] * df_work['FR']

print(f"   ‚úì Features derivadas creadas")

# ============================================================
# 5. PREPARAR MATRIZ X, y_true
# ============================================================
print("\nüìä Preparando datos para predicci√≥n...")

# Extraer features que el modelo espera
X = df_work[metadata['features']].copy()

# Etiquetas verdaderas
label_to_int = metadata['label_to_int']
int_to_label = metadata['int_to_label']

y_true = df_work['Validacion'].map(label_to_int).values

print(f"   ‚úì Features preparadas: {len(metadata['features'])}")
print(f"   ‚úì Casos a evaluar: {len(X)}")

# ============================================================
# 6. PREDICCI√ìN
# ============================================================
print("\nü§ñ Generando predicciones...")

y_pred = modelo.predict(X)
y_pred_proba = modelo.predict_proba(X)

# Confianza (probabilidad m√°xima)
confianza = y_pred_proba.max(axis=1)

print(f"   ‚úÖ Predicciones completadas")
print(f"   Confianza promedio: {confianza.mean()*100:.1f}%")

# ============================================================
# 7. EVALUACI√ìN
# ============================================================
print("\n" + "="*80)
print("üìä RESULTADOS DE EVALUACI√ìN")
print("="*80)

# Accuracy
accuracy = accuracy_score(y_true, y_pred)

print(f"\nüéØ ACCURACY: {accuracy:.4f} ({accuracy*100:.2f}%)")

# Cantidad de aciertos
aciertos = (y_true == y_pred).sum()
total = len(y_true)

print(f"\n   ‚úÖ Aciertos: {aciertos}/{total}")
print(f"   ‚ùå Errores: {total - aciertos}/{total}")

# Classification Report
print(f"\nüìã CLASSIFICATION REPORT:")
print("="*80)
print(classification_report(y_true, y_pred, target_names=['NO PERTINENTE', 'PERTINENTE']))

# Confusion Matrix
print(f"\nüî¢ CONFUSION MATRIX:")
print("="*80)
cm = confusion_matrix(y_true, y_pred)

print(f"\n                     Predicho")
print(f"                     NO PERT    PERTINENTE")
print(f"   Real NO PERT        {cm[0][0]:>6}     {cm[0][1]:>6}")
print(f"   Real PERTINENTE     {cm[1][0]:>6}     {cm[1][1]:>6}")

# M√©tricas por clase
print(f"\nüìà M√âTRICAS DETALLADAS:")
print("="*80)

# Para NO PERTINENTE
vn = cm[0][0]  # Verdaderos Negativos
fp = cm[0][1]  # Falsos Positivos
fn = cm[1][0]  # Falsos Negativos
vp = cm[1][1]  # Verdaderos Positivos

# NO PERTINENTE
if (vn + fp) > 0:
    precision_no_pert = vn / (vn + fn) if (vn + fn) > 0 else 0
    recall_no_pert = vn / (vn + fp) if (vn + fp) > 0 else 0
    print(f"\n   NO PERTINENTE:")
    print(f"      Casos reales: {vn + fp}")
    print(f"      Bien clasificados: {vn}")
    print(f"      Mal clasificados: {fp} (predichos como PERTINENTE)")
    print(f"      Precisi√≥n: {precision_no_pert*100:.1f}%")

# PERTINENTE
if (vp + fn) > 0:
    precision_pert = vp / (vp + fp) if (vp + fp) > 0 else 0
    recall_pert = vp / (vp + fn) if (vp + fn) > 0 else 0
    print(f"\n   PERTINENTE:")
    print(f"      Casos reales: {vp + fn}")
    print(f"      Bien clasificados: {vp}")
    print(f"      Mal clasificados: {fn} (predichos como NO PERTINENTE)")
    print(f"      Recall: {recall_pert*100:.1f}%")

# ============================================================
# 8. AN√ÅLISIS DE ERRORES
# ============================================================
print(f"\n" + "="*80)
print("üîç AN√ÅLISIS DE ERRORES")
print("="*80)

# Casos mal clasificados
errores = df_work[y_true != y_pred].copy()
errores['Prediccion'] = [int_to_label[p] for p in y_pred[y_true != y_pred]]
errores['Real'] = errores['Validacion']
errores['Confianza'] = confianza[y_true != y_pred]

if len(errores) > 0:
    print(f"\n   Total errores: {len(errores)}")
    print(f"\n   Primeros 10 errores:")
    print(f"   {'Episodio':<15} {'Real':<15} {'Predicho':<15} {'Confianza':<10}")
    print("   " + "-"*60)
    
    for i, row in errores.head(10).iterrows():
        episodio = str(row.get('Episodio', 'N/A'))[:13]
        real = row['Real']
        pred = row['Prediccion']
        conf = row['Confianza']
        print(f"   {episodio:<15} {real:<15} {pred:<15} {conf*100:>6.1f}%")
    
    # Guardar errores en CSV
    errores[['Episodio', 'Real', 'Prediccion', 'Confianza']].to_csv(
        'errores_form_mpp.csv', index=False
    )
    print(f"\n   üíæ Errores guardados en: errores_form_mpp.csv")
else:
    print(f"\n   ‚úÖ ¬°Sin errores! Predicci√≥n perfecta")

# ============================================================
# 9. GUARDAR PREDICCIONES COMPLETAS
# ============================================================
print(f"\nüíæ Guardando predicciones completas...")

df_resultados = df.copy()
df_resultados['Prediccion_IA'] = np.nan
df_resultados['Confianza_IA'] = np.nan

# Asignar predicciones solo a los casos evaluados
indices_evaluados = df_con_validacion.index
df_resultados.loc[indices_evaluados, 'Prediccion_IA'] = [int_to_label[p] for p in y_pred]
df_resultados.loc[indices_evaluados, 'Confianza_IA'] = confianza * 100

df_resultados.to_excel('form_MPP_con_predicciones.xlsx', index=False)

print(f"   ‚úÖ Predicciones guardadas: form_MPP_con_predicciones.xlsx")

# ============================================================
# 10. RESUMEN FINAL
# ============================================================
print("\n" + "="*80)
print("‚úÖ EVALUACI√ìN COMPLETADA")
print("="*80)

print(f"""
RESUMEN:
   ‚Ä¢ Total casos en form_MPP.xlsx: {len(df):,}
   ‚Ä¢ Casos CON validaci√≥n (evaluados): {len(df_con_validacion):,}
   ‚Ä¢ Casos SIN validaci√≥n: {len(df) - len(df_con_validacion):,}
   
RESULTADOS:
   ‚Ä¢ Accuracy: {accuracy*100:.2f}%
   ‚Ä¢ Aciertos: {aciertos}/{total}
   ‚Ä¢ Errores: {total - aciertos}/{total}
   
ARCHIVOS GENERADOS:
   ‚Ä¢ form_MPP_con_predicciones.xlsx (todas las predicciones)
   ‚Ä¢ errores_form_mpp.csv (an√°lisis de errores)
""")

print("="*80)
